{"cells":[{"cell_type":"markdown","id":"straight-people","metadata":{"id":"straight-people"},"source":["<p style=\"text-align: center;\" ><font size=\"+3\"><u><b>Laboratory 1 Part 1: Introduction to Imaging</u></b></p>"]},{"cell_type":"markdown","id":"weird-savings","metadata":{"id":"weird-savings"},"source":["<p style=\"text-align: left;\" ><font size=\"+1\"><b>Objectives</b></p>"]},{"cell_type":"markdown","id":"sexual-eligibility","metadata":{"id":"sexual-eligibility"},"source":["<div class=\"alert alert-block alert-warning\">\n","<font color=black>\n","\n","- Learn how to build a basic microscope\n","- Familiarize with stage and camera control (Exposure, focusing, lighting control)\n","- Acquire an image of a biological slide\n","\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"south-theory","metadata":{"id":"south-theory"},"source":["<p style=\"text-align: left;\" ><font size=\"+1\"><b>Introduction / Basic Rules</b></p>"]},{"cell_type":"markdown","id":"elementary-overhead","metadata":{"id":"elementary-overhead"},"source":["<div class=\"alert alert-block alert-warning\">\n","<font color='black'> The first part of this laboratory is a tutorial to get familiar with your optical kit. The following is a step-by-step process describing how to assemble a basic microscope. <br/> A number of basic rules apply to the handling of this kit. These rules include:\n","\n","\n","- Any glass element in the kit should be handled carefully by the edges. Never place fingers on a surface through which light for imaging passes. This includes imaging targets and slides.\n","- Dust and oils are bad for most optical elements and the camera. Avoid having the interior of the objective lens and the uncovered camera exposed for any length of time. Never touch the camera sensor.\n","- Nothing in your kit should require a large amount of force to assemble or disassemble. If something isn’t going together easily, there’s probably something wrong. Never force any elements that aren’t moving easily. If there are problems, ask the instructor or TA for help.\n","- Please be a good custodian of your optical hardware kit. The kit is your responsibility for the duration of the course. With proper care these kits should be able to be used for many years. Thank you for your help in making this possible.\n","- If any element of your kit appears damaged or if something doesn’t appear right, contact the instructor or TA immediately.\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"outside-blues","metadata":{"id":"outside-blues"},"source":["# Microscope assembly\n","\n","<div class=\"alert alert-block alert-warning\">\n","<font color='black'> We will begin this lab by assembling a basic microscope. You are provided with all of the hardware elements that are required to construct this imaging device. The figure below shows a complete inventory of all of the hardware elements in your optical kit. Take a moment to ensure all of the parts are present in your kit and to learn some of the nomenclature for the various elements. <br/> <br/>\n","In addition to the parts in the picture below, you will have access to a computer, a power supply for the lighting module, and a number of imaging targets.\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"independent-faith","metadata":{"id":"independent-faith"},"source":["<img src=\"Lab1\\Inventory.png\" style=\"width:800px\">"]},{"cell_type":"markdown","id":"exposed-overview","metadata":{"id":"exposed-overview"},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Step 1: Construct the linear stage assembly.</b> <font color='black'> <br/>\n","\n","First, we begin assembly of the imaging platform. This platform will hold the microscope stage and can be moved vertically to focus the imaging plane. We begin by affixing a mounting plate adapter to the linear stage using four shorter, silver ¼-20 machine screws. These should be hand-tightened using an appropriate Allen wrench. Note the orientation of the adapter plate. Once affixed, the 1” mount plate should be attached to the silver adapter plate using four 8-32 screws. Again, note the orientation of the mount – the 1” diameter channel in the mount plate should be parallel to the direction of travel of the linear stage. Lastly, prepare a (8” length) 1” diameter post by placing a ¼-20 set screw in one end of the post. Note that the set screw should have the Allen head <i> facing outward</i>.\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"impaired-league","metadata":{"id":"impaired-league"},"source":["<img src=\"Lab1\\Step1.png\" style=\"width:700px\">"]},{"cell_type":"markdown","id":"martial-isolation","metadata":{"id":"martial-isolation"},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Step 2: Affix main support posts and continue stage assembly </b> <font color='black'> <br/>\n","    \n","Pick a location relatively close to the edge of your breadboard centered along the short side of the platform. Screw the 1” post into the breadboard using the previously placed set screw. Loosen the screw on the 1” mount plate and pace the linear stage assembly on the 1” post as shown below. Align the linear stage to the breadboard grid and tighten the mount clamp. <br/><br/>\n","Prepare a second 16”-long post using two set screws – one to connect two posts together; and another to fix the combined 16” post to the breadboard. Affix the post 10” from the 8”-long post that will hold the microscope stage. (Note that the breadboard has tapped holes with 1” spacing.) <br/><br/>\n","Using four longer ¼-20 screws, attach the two L-brackets to the linear stage. Note that these brackets have a righthandside and lefthandside, and a top and a bottom. A notch should appear toward the center, top of the bracket as shown below. The hole patterns are also asymmetric and can only be assembled with the top, up. Only tighten these screws enough to hold on the brackets. We will fully tighten them once the microscope stage is attached.\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"further-render","metadata":{"id":"further-render"},"source":["<img src=\"Lab1\\Step2.png\" style=\"width:700px\">"]},{"cell_type":"markdown","id":"retained-renewal","metadata":{"id":"retained-renewal"},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Step 3: Finish microscope stage assembly</b> <font color='black'> <br/>\n","    \n","Next we attach the microscope stage to the linear stage. Handle the microscope stage with care. There is a large glass window in the stage that is fragile. Moreover, scratching this stage or getting excess dust or debris on the stage will complicate future experiments. This stage is held on with four more ¼-20 screws. Once you’ve gotten these screws place and started, you may tighten all eight screws on the two L-brackets. You should have just enough room for the stage between the two upright 1” posts. If necessary, you may need to adjust the knob on the stage which controls XY position. </font>\n","</div>"]},{"cell_type":"markdown","id":"charged-eligibility","metadata":{"id":"charged-eligibility"},"source":["<img src=\"Lab1\\Step3.png\" style=\"width:700px\">"]},{"cell_type":"markdown","id":"bulgarian-burning","metadata":{"id":"bulgarian-burning"},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Step 4: Assemble the lens-camera system components</b> <font color='black'> <br/>\n","    \n","In the next step we begin the assembly of the optical path of the imaging system. The major elements here are the objective lens, an optical tube assembly and the camera. These elements are more fragile that items in the previous steps and require additional care. <br/> <br/>\n","The lens is threaded differently than the optical tubes and requires an adapter. Place that adapter on the lens and hand tighten. A manual aperture (iris) may then be affixed to the back of the lens followed by an optical tube. For this lab, start with an optical tube of 1” length. <br/> <br/>\n","The camera is also threaded differently than the optical tubes and requires its own adapter. Hand tighten that adapter and place a ½” optical tube on the camera assembly. To the optical tube, the filter wheel assembly may be attached, followed by a 2” optical tube.\n","\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"curious-mozambique","metadata":{"id":"curious-mozambique"},"source":["<img src=\"Lab1\\Step4.png\" style=\"width:900px\">"]},{"cell_type":"markdown","id":"established-twenty","metadata":{"id":"established-twenty"},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Step 5: Mount lens-camera system</b> <font color='black'>  <br/>\n","    \n","The lens-tube-camera assembly is held in place by two optical tube mounts. Each of these is composed of the tube mount, a ½” diameter post, and a right-angle mount that attaches to the taller 1” post. Assemble each tube mount and roughly position the posts to accept the lens-tube-camera assembly. <br/><br/>\n","    \n","<b><i> NOTE: Do not allow the tube mounts or the tube assembly to fall onto the glass platform of the microscope stage. You can break the glass in the platform if these drop from a significant height. </b></i> <br/><br/>\n","    \n","    \n","Place the lens-tube half of the assembly in the bottom mount and the tube-camera assembly in the upper mount and screw them together. Make fine adjustments to the lens-tube-camera assembly ensuring that: <br/>\n","\n","- The tube assembly is aligned with the circular hole in the bottom of the microscope stage.\n","- The optical tube assembly is vertical and parallel to the 1” support post. <br/>\n","\n","Once positioned, hand tighten the screws that hold the right angle mounts to the 1” and ½” posts. And, tighten the optical tube mounts to secure the lens-tube-camera assembly.\n","\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"approved-palestine","metadata":{"id":"approved-palestine"},"source":["<img src=\"Lab1\\Step5.png\" style=\"width:800px\">"]},{"cell_type":"markdown","id":"promising-criticism","metadata":{"id":"promising-criticism"},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Step 6: Add the illumination module</b> <font color='black'> <br/>\n","    \n","Next, we will be attaching the lighting module to the microscope. This module is composed of three elements. A support arm, a coupler, and the lighting module itself. The support arm is attached to the linear stage using two ¼-20 screws. It should fit securely between the L-brackets at the lowest available screw positions (see below). The coupler and the light module slide together as shown below. <br/><br/>\n","   \n","<b><i> Do not apply significant pressure to the support arm. It is sufficient strong to hold the lighting module but will break easily if used to lift the stage, used as a brace for fastening screws, etc. </b></i>\n","    \n","</font>\n","</div>"]},{"cell_type":"markdown","id":"laughing-granny","metadata":{"id":"laughing-granny"},"source":["<img src=\"Lab1\\Step6.png\" style=\"width:700px\">"]},{"cell_type":"markdown","id":"victorian-composer","metadata":{"id":"victorian-composer"},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Step 7: Align the lighting module and add a diffuser</b> <font color='black'> <br/>\n","    \n","<b><i> Note that the lighting module is quite bright. Do not look directly into the LED light.</b></i><br/><br/>\n","    \n","The light module may be activated by plugging in the provided power supply.  A brightness adjustment is provided on the side of the module for some control. Note that there is a lower threshold where the LED will not light. The glass diffuser should be placed in the channel created by the two L-brackets.<b><i> This diffuser should slide in easily. </b></i>If it does not, contact the instructor. Also note that this diffuser can slide out easily. <b><i>Move your microscope with care to avoid letting the diffuser fall out and break. </b></i><br/><br/>\n","The position of the light module should be adjusted so that the circular illumination covers the circular hole in the bottom of the microscope stage.<br/><br/>\n","Adjust the illumination at a low setting where the LED light is on and stable.\n","\n","    \n","</font>\n","</div>"]},{"cell_type":"markdown","id":"social-court","metadata":{"id":"social-court"},"source":["<img src=\"Lab1\\Step7.png\" style=\"width:700px\">"]},{"cell_type":"markdown","id":"genetic-engagement","metadata":{"id":"genetic-engagement"},"source":["<div class=\"alert alert-block alert-warning\">\n","<b>Step 8: Start imaging – refine microscope set up and start experimenting</b> <font color='black'> <br/>\n","Connect the camera to your computer using the provided cable. Note that a USB 3.0 port is required for reliable communication. There should be a green light on the camera if everything is working properly. <br>   \n","You should now be ready to start imaging with your microscope. To start taking images, place an imaging target or microscope slide on the stage. (See below.)<br/><br/>\n","<b><i>IMPORTANT: While stage clips are provided to hold a slide in place, the clips should NEVER be placed on the part of the slide with a sample, and NEVER used on the resolution target at all.</b></i>\n","    \n","\n","</font>\n","</div>\n"]},{"cell_type":"markdown","id":"horizontal-brooks","metadata":{"id":"horizontal-brooks"},"source":["<img src=\"Lab1\\Step8.png\" style=\"width:1000px\">"]},{"cell_type":"markdown","id":"traditional-genius","metadata":{"id":"traditional-genius"},"source":["## Test the Camera Module"]},{"cell_type":"code","execution_count":1,"id":"da18c5c0","metadata":{"id":"da18c5c0","executionInfo":{"status":"ok","timestamp":1743565954426,"user_tz":240,"elapsed":11,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}}},"outputs":[],"source":["# add BaITools to path\n","import os\n","import sys\n","sys.path.insert(0,r'BaITools')"]},{"cell_type":"code","execution_count":2,"id":"323c41d1","metadata":{"id":"323c41d1","executionInfo":{"status":"error","timestamp":1743565954609,"user_tz":240,"elapsed":184,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}},"outputId":"abdcefd3-9a63-46fd-b907-9d82a924cae2","colab":{"base_uri":"https://localhost:8080/","height":349}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'zelux'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-e825654e29ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'font.size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m   \u001b[0;31m# set the font size globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mzelux\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZeluxCamera\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mCamera\u001b[0m \u001b[0;31m# for camera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'zelux'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# for basic functions\n","import numpy as np\n","from time import sleep\n","import matplotlib.pyplot as plt\n","from IPython.display import display, clear_output\n","import cv2\n","plt.rcParams['font.size'] = 16   # set the font size globally\n","\n","from zelux import ZeluxCamera as Camera # for camera"]},{"cell_type":"code","execution_count":null,"id":"historical-witness","metadata":{"id":"historical-witness","executionInfo":{"status":"aborted","timestamp":1743565954577,"user_tz":240,"elapsed":213,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}}},"outputs":[],"source":["print('Camera initialized as c')\n","c = Camera()\n","c.open()"]},{"cell_type":"code","execution_count":null,"id":"incomplete-commitment","metadata":{"id":"incomplete-commitment","executionInfo":{"status":"aborted","timestamp":1743565954583,"user_tz":240,"elapsed":214,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}}},"outputs":[],"source":["# check image properties\n","c.get_properties()\n","c.set_exposure(10)\n","c.get_exposure()\n","c.set_framerate(2)\n","c.get_framerate()"]},{"cell_type":"markdown","id":"4f67de5b","metadata":{"id":"4f67de5b"},"source":["Create a script with the following commands. <br/> You should now see a figure with a live image from the camera. The image is likely blurry since you have not yet adjusted the focus."]},{"cell_type":"code","execution_count":null,"id":"e5305a8e-65c3-4509-89c5-4eca814775b4","metadata":{"id":"e5305a8e-65c3-4509-89c5-4eca814775b4","executionInfo":{"status":"aborted","timestamp":1743565954584,"user_tz":240,"elapsed":214,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}}},"outputs":[],"source":["# try continuous capture\n","# to quit press live feed press \"q\"\n","while True:\n","    # Convert the image from 10-bit to 8-bit and then display the image.\n","     cv2.imshow('Camera', cv2.normalize(c.capture().copy(), None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U))\n","     if cv2.waitKey(30) & 0xFF == ord('s'):\n","        test_im = c.capture().copy()\n","        fig, ax = plt.subplots(1, figsize=(12, 5))\n","        x = ax.imshow(test_im, cmap='gray')\n","        fig.colorbar(x, ax=ax)\n","        plt.savefig('savedimage.png')\n","        if cv2.waitKey(30) & 0xFF == ord('q'):\n","            break\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"id":"9a288290","metadata":{"id":"9a288290","executionInfo":{"status":"aborted","timestamp":1743565954585,"user_tz":240,"elapsed":215,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}}},"outputs":[],"source":["# acquire and plot a single image now\n","test_im = c.capture().copy()\n","fig, ax = plt.subplots(1, figsize=(12, 5))\n","x = ax.imshow(test_im, cmap='gray')\n","fig.colorbar(x, ax=ax)\n","plt.savefig('savedimage.png')"]},{"cell_type":"code","execution_count":null,"id":"devoted-cheat","metadata":{"id":"devoted-cheat","executionInfo":{"status":"aborted","timestamp":1743565954586,"user_tz":240,"elapsed":215,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}}},"outputs":[],"source":["c.close()"]},{"cell_type":"markdown","id":"tamil-elephant","metadata":{"id":"tamil-elephant"},"source":["# Focusing and image formatting"]},{"cell_type":"markdown","id":"entitled-surface","metadata":{"id":"entitled-surface"},"source":["<div class=\"alert alert-block alert-warning\">\n","<font color='black'> To change the focus, you rotate the screw adjustment on the linear stage (see below). In the remote setup, this is accomplished by moving the z-stage (variable name stage_z from above). <br/><br/>\n","    \n","<b><i>IMPORTANT: This knob should rotate freely, if you experience resistance stop immediately. Note that you can drive the microscope stage into the lens if you are not careful (damaging the lens or microscope stage or target). Best practice is to focus “away from the lens.” That is start with the stage near the lens and move the stage downward.</b></i><br/><br/>\n","Practice finding the in-focus image for your target. Best focus is most easily found by looking at the sharpness of features (e.g. edges) in your image. If you are having difficulty, ask the instructor for help.<br/><br/>\n","If you cannot find a good in-focus image and your image is mostly dark or mostly white, jump ahead to “adjusting signal levels”.<br/><br/>\n","Your image is likely rotated and/or flipped relative to its position on the microscope stage. To fix this will require both hardware and software modifications. First, you should rotate the lens-camera assembly to be aligned with the XY-motion axes. This should be accomplished by loosening the tube clamps only (see below). <b><i>WARNING: Do not let the tube assembly drop and fall on the microscope stage. Hand tighten clamps once the assembly is aligned.</b></i>\n","\n","    \n","Your images are potentially rotated, flipped, or transposed. Modify your script by applying `np.rot90(img)`, `np.transpose(img)`, `np.fliplr(img)`, and/or `np.flipud(img)` commands. </font>\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"turned-calibration","metadata":{"id":"turned-calibration"},"source":["<img src=\"Lab1\\FocusingKnob.png\" style=\"width:1000px\">"]},{"cell_type":"markdown","id":"cd0f4b4f-6c67-4243-b13c-761c27cd6dfb","metadata":{"id":"cd0f4b4f-6c67-4243-b13c-761c27cd6dfb"},"source":[]},{"cell_type":"code","execution_count":null,"id":"f981dddf-86e1-43f0-8e6b-6d9d64a90f7a","metadata":{"id":"f981dddf-86e1-43f0-8e6b-6d9d64a90f7a","executionInfo":{"status":"aborted","timestamp":1743565954586,"user_tz":240,"elapsed":212,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"genetic-oxide","metadata":{"id":"genetic-oxide"},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Data collection:</b> <font color='black'> Collect a series of images at different levels of focus. <br/><br/>\n","1. Which image would you consider is in focus? Show the in-focus below with x, y axis labels (in pixels) and a colorbar.    \n","</font>\n","</div>"]},{"cell_type":"markdown","id":"d155e0aa-f8c0-4780-be75-0a78a518fad7","metadata":{"id":"d155e0aa-f8c0-4780-be75-0a78a518fad7"},"source":["![focused.png](attachment:dc1aa6a8-f43d-4e61-99f0-2b43c1645c9f.png)\n"]},{"cell_type":"markdown","id":"varied-boutique","metadata":{"id":"varied-boutique"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 2. Why do you think this image is in focus? (Be specific and describe what features you are looking at. Provide a zoomed image to illustrate these features.) </font>\n","\n","</div>"]},{"cell_type":"markdown","id":"ca02ee32-56e2-473a-a5e7-800237cf446d","metadata":{"id":"ca02ee32-56e2-473a-a5e7-800237cf446d"},"source":["The light rays at each object point convert on the imaging plane. The image is sharp and has crisp boundaries. THe aperture is set at the max to allow for the highest resultion image."]},{"cell_type":"markdown","id":"beneficial-arthritis","metadata":{"id":"beneficial-arthritis"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 3. Pick an out-of-focus image and show it below. How is this image different to the in-focus image you showed above? </font>\n","\n","</div>"]},{"cell_type":"markdown","id":"a9be1bba-68fc-4b9a-8a66-86ed7c0f421c","metadata":{"id":"a9be1bba-68fc-4b9a-8a66-86ed7c0f421c"},"source":["*italicized text*![nonfocusedimage.png](attachment:f25e97f3-9838-4202-a87c-56b074e0f53c.png)"]},{"cell_type":"markdown","id":"14e324c0-f2f4-44d3-8b0d-f070c1014da5","metadata":{"id":"14e324c0-f2f4-44d3-8b0d-f070c1014da5"},"source":["![unfocused.png](attachment:d2436ae9-800b-491a-9a9c-83de3487b2ce.png)"]},{"cell_type":"markdown","id":"47989f2d-ff32-48c5-bd2d-8c0eafe614ec","metadata":{"id":"47989f2d-ff32-48c5-bd2d-8c0eafe614ec"},"source":["The rays from a single point on the object are spread out when they reach the camera lens, creating a blurry image."]},{"cell_type":"markdown","id":"associate-fossil","metadata":{"id":"associate-fossil"},"source":["# Adjusting image signal levels"]},{"cell_type":"markdown","id":"caroline-brush","metadata":{"id":"caroline-brush"},"source":["<div class=\"alert alert-block alert-warning\">\n","<font color='black'>\n","The data that is acquired by your camera is 10-bit. This means that the camera is capable of reporting values between 0 and 1023. Generally, you will want to collect data that covers most of this range. The following terms will be important to know: <br/>\n","\n","- <b> Underexposure </b>– A lack of integrated signal at the detector. Most of the values will be on the low end of the 0-1023 range. Python will automatically scale the colorbar to range between the minimum and maximum values, so the image won’t necessarily appear dark; however, increased noise will be apparent. <br/>\n","\n","- <b> Saturation </b> - The camera cannot represent signal levels above 1023. Thus, signal levels above that range will “saturate” (or be limited) at 1023. This results in a loss of contrast for any image regions above that level. <br/>\n","\n","- <b> Overexposure </b>– Too much signal is also a problem for image quality. Generally overexposed images will exhibit saturation in some part of the image. <br/>\n","- <b> “Good” exposure </b>– This is somewhat qualitative; however, a “good” exposure should not be underexposed (too noisy) and should not have any saturated regions. e.g. All pixel values fall in the range 0-950.\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"english-accordance","metadata":{"id":"english-accordance"},"source":["<div class=\"alert alert-block alert-warning\">\n","<font color='black'> There are three basic ways to change the signal level in your imaging system: <br/>\n","\n","- <b> Changing the illumination level </b> - The lighting module has an adjustment that permits changing the brightness of the LED illumination. <br/>\n","- <b> Changing the size of the aperture </b> - An adjustable iris has been installed right above the lens. This aperture controls the diameter of the light beam that is exiting the rear side of the lens. Smaller apertures will reduce signal levels and larger apertures will increase signal levels. <br/>\n","- <b> Changing the exposure time </b>– Your camera has the ability to adjust the integration time over which signal is measured for individual images. The current setting can be found by looking at the Python camera object. (The variable `c` in your python script above.) You may set this value using the statement, for example, `c.set_exposure(10)`. This sets the exposure to 10 milliseconds. Longer integration times permit accrual of more signal, while shorter exposure times result in less signal. The maximum exposure time is limited by the camera framerate (also adjustable). For example, changing framerate with `c.set_framerate(1)` sets the rate to 1 frame/second permitting exposures up to 1000 ms. <br/>"]},{"cell_type":"markdown","id":"southwest-bridal","metadata":{"id":"southwest-bridal"},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Exposure and illumination experiments:</b> <br/> <font color='black'> Place a biological slide on your microscope. Set your LED illumination to the lowest stable setting.  Open your aperture to the widest setting. Move the filter wheel to one of the open (no filter) settings. <br/><br/>\n","\n","Finding a good exposure setting for your image involves finding the maximum values in your image. While one could simply using Python’s `np.max()` function, this is sensitive to noise and single “bright” pixels. A better solution is to plot a histogram of pixel values and then select an exposure that yields a minimal number of saturated values. In the following cell, write code that will show an image from the microscope as well as its histogram of pixel values (with 1024 intensity bins).\n","</font>\n","</div>"]},{"cell_type":"code","execution_count":3,"id":"sitting-programmer","metadata":{"id":"sitting-programmer","outputId":"59e6a8d2-e481-430e-8f6e-fb56907e124f","executionInfo":{"status":"error","timestamp":1743565964065,"user_tz":240,"elapsed":58,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}},"colab":{"base_uri":"https://localhost:8080/","height":211}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'c' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ecd72de270e5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exposure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_10bit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"]}],"source":["c.set_exposure(10)\n","\n","image_10bit = c.capture().copy()\n","\n","\n","image_8bit = cv2.normalize(image_10bit, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","\n","cv2.imshow('Microscope Image', image_8bit)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n","\n","\n","for i in range(10):\n","\n","    exposure = 5 * i\n","    c.set_exposure(exposure)\n","\n","    sleep(5)\n","    real_exposure = c.get_exposure()\n","    print(real_exposure)\n","\n","    image_10bit = c.capture().copy()\n","    image_8bit = cv2.normalize(image_10bit, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","\n","    fig, ax = plt.subplots(1, figsize=(12, 5))\n","    x = ax.imshow(image_8bit, cmap='gray')\n","    fig.colorbar(x, ax=ax)\n","    plt.savefig(f\"image_exposure{exposure}.png\")  # Save the image\n","\n","    plt.clf()\n","\n","    fig, ax = plt.subplots(figsize=(12, 5))\n","    ax.hist(image_10bit.flatten(), bins=1024, range=(0, 1023), color='gray')\n","    ax.set_xlabel('Pixel Value (0–1023)')\n","    ax.set_ylabel('Frequency')\n","    ax.set_title(f'Histogram at Exposure {exposure} ms')\n","    plt.tight_layout()\n","\n","    plt.savefig(f'histogram_exposure{exposure}.png')\n","    plt.show()\n","\n","    plt.clf()\n","    plt.cla()\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"193881ac-8f6f-4bd8-ab3e-c80338334e66","metadata":{"id":"193881ac-8f6f-4bd8-ab3e-c80338334e66"},"source":["We chose exposure 30 ms based on the histogram plots (max frequency)."]},{"cell_type":"markdown","id":"88052f44-5939-48d3-a70c-94c896875d25","metadata":{"id":"88052f44-5939-48d3-a70c-94c896875d25"},"source":["![image_exposure20.png](attachment:13a235ed-64ff-4288-8be0-5399cc96a768.png)"]},{"cell_type":"markdown","id":"532aef61-d848-4a1b-a315-04514ef1dcf2","metadata":{"id":"532aef61-d848-4a1b-a315-04514ef1dcf2"},"source":["^exposure 20 ms"]},{"cell_type":"markdown","id":"cdd9768e-0374-4bc7-9587-65a9be2397f5","metadata":{"id":"cdd9768e-0374-4bc7-9587-65a9be2397f5"},"source":["![image_exposure30.png](attachment:ac5da753-d39a-439e-a749-8243fd202a65.png)"]},{"cell_type":"markdown","id":"1cb0600a-d89d-4cae-89b9-d27b95f1dfe9","metadata":{"id":"1cb0600a-d89d-4cae-89b9-d27b95f1dfe9"},"source":["^exposure 30 ms"]},{"cell_type":"markdown","id":"753b39bb-ad25-400d-8e17-7117894cae77","metadata":{"id":"753b39bb-ad25-400d-8e17-7117894cae77"},"source":["![image_exposure35.png](attachment:c8980df9-29dd-4708-83f2-fb6c893950e2.png)"]},{"cell_type":"markdown","id":"640f7f50-387b-444e-ba62-4b63248eff4b","metadata":{"id":"640f7f50-387b-444e-ba62-4b63248eff4b"},"source":["^exposure 35 ms"]},{"cell_type":"markdown","id":"857bda84-00b8-4ae8-b8b1-c94659e3a4e7","metadata":{"id":"857bda84-00b8-4ae8-b8b1-c94659e3a4e7"},"source":["![histogram_aperture20.png](attachment:4a923b9a-b2a5-4e5e-a745-ee1ba91a0dc6.png)"]},{"cell_type":"markdown","id":"54461a41-4510-42d6-a6b7-9c71b3d02d99","metadata":{"id":"54461a41-4510-42d6-a6b7-9c71b3d02d99"},"source":["![histogram_aperture25.png](attachment:bd915396-290c-40dd-9708-cce35f0e46ae.png)"]},{"cell_type":"markdown","id":"b8d9a876-a46e-4a3f-bb6a-a30d95efabaf","metadata":{"id":"b8d9a876-a46e-4a3f-bb6a-a30d95efabaf"},"source":["![histogram_exposure30.png](attachment:a4a1bd47-f086-427d-bfad-e2650feb30c8.png)"]},{"cell_type":"markdown","id":"75fd3c11-f83a-435a-98a6-de31ea25cc4f","metadata":{"id":"75fd3c11-f83a-435a-98a6-de31ea25cc4f"},"source":["![histogram_exposure0.png](attachment:64e3ab02-2715-4573-8fa3-b85c3534e5cf.png)![histogram_exposure5.png](attachment:3d5c03db-f0c6-44f1-9819-6e165cc5ec61.png)![histogram_exposure10.png](attachment:8cfd7c02-da3a-437f-83a4-e83bb76c296f.png)![histogram_exposure15.png](attachment:3d5d2036-868a-4e7a-beaa-77d2987bcbc9.png)![histogram_exposure20.png](attachment:cf1db1ae-9d6d-4e72-bdb4-f0b42b02c0c3.png)![histogram_exposure25.png](attachment:4e6f7104-d892-460c-ba9f-e77a4b6bdcf7.png)![histogram_exposure35.png](attachment:1930e092-b69d-4958-bb02-779ef6ae4dde.png)"]},{"cell_type":"markdown","id":"70392068-3257-4247-9729-e8ac64a94be9","metadata":{"id":"70392068-3257-4247-9729-e8ac64a94be9"},"source":["![averagedhistogram_aperture.png](attachment:c401bc6b-5516-4525-9f6c-9db67d441f44.png)"]},{"cell_type":"markdown","id":"pharmaceutical-breakdown","metadata":{"id":"pharmaceutical-breakdown"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<b>Data collection:</b> <font color='black'> Collect a series of images at different levels of exposure. <br/><br/> DOUBLE CHECK Use `sleep(5)` and `print(c.get_exposure())` after setting exposure to ensure the correct exposure level is reached. </font>\n","</div>"]},{"cell_type":"markdown","id":"9406e33f-180d-468d-8d6b-21adca4cdef1","metadata":{"id":"9406e33f-180d-468d-8d6b-21adca4cdef1"},"source":["refer to code under \"Exposure and illumination experiments:\""]},{"cell_type":"markdown","id":"capable-indian","metadata":{"id":"capable-indian"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 1. What is a good exposure setting for this scenario?  <br/>\n","Show an image of the slide at these settings and paste it below:    \n","</font>\n","\n","</div>"]},{"cell_type":"markdown","id":"2be45009-4164-4c39-b7db-c2f10355c9f3","metadata":{"id":"2be45009-4164-4c39-b7db-c2f10355c9f3"},"source":["exposure 30 ms"]},{"cell_type":"markdown","id":"aca66690-b0b2-41d2-8788-fdfed415f512","metadata":{"id":"aca66690-b0b2-41d2-8788-fdfed415f512"},"source":["![image_exposure30.png](attachment:2cde2456-5e7e-4588-8d8e-0472766330de.png)"]},{"cell_type":"markdown","id":"bizarre-nelson","metadata":{"id":"bizarre-nelson"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 2. Justify why this image represents a good exposure (include a gray level histogram as part of your discussion): </font>\n","\n","</div>"]},{"cell_type":"markdown","id":"3f3d672b-9929-4d37-8d49-89f3b5fac35a","metadata":{"id":"3f3d672b-9929-4d37-8d49-89f3b5fac35a"},"source":["This image represents a good exposure because it has a minimal number of saturated values (no spikes at the high end 1023 which indicates saturation). There are also no significant values clustered near zero, which means underexposure. This balance means the image captures a wide dynamic range, which maximizes contrast and detail without clipping. The visual also supports the histogram."]},{"cell_type":"markdown","id":"infrared-europe","metadata":{"id":"infrared-europe"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 3. Show an image of the slide where there is obvious saturation: </font>\n","\n","</div>"]},{"cell_type":"markdown","id":"02d9f23c-7dd6-42ba-bf85-48f219c9074b","metadata":{"id":"02d9f23c-7dd6-42ba-bf85-48f219c9074b"},"source":["![image_exposure30.png](attachment:4fd96e9a-e32d-45a8-b1d1-0544c28a1e00.png)"]},{"cell_type":"markdown","id":"broken-stress","metadata":{"id":"broken-stress"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 4. How can you tell that this image is saturated? Why is it saturated?  </font>\n","\n","</div>"]},{"cell_type":"markdown","id":"792fcdd3-9c24-4978-96f8-2687a48085b8","metadata":{"id":"792fcdd3-9c24-4978-96f8-2687a48085b8"},"source":["The image is saturated because the histogram shows a sharp peak at the maximum pixel value (1023). This indicates that some regions in the image received more signal than the camera could accurately represent."]},{"cell_type":"markdown","id":"faced-seattle","metadata":{"id":"faced-seattle"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 5. What is the relationship between exposure and maximum pixel value? Plot this for the data we collected and describe. </font>\n","\n","</div>"]},{"cell_type":"markdown","id":"4593e0f7-4ae6-4505-83eb-e248964b12cb","metadata":{"id":"4593e0f7-4ae6-4505-83eb-e248964b12cb"},"source":["As exposure time increases, the maximum pixel value also increases. This is roughly represented by a non-linear curve that flattens once saturation begins. Initially, there should be an almost linear relationship where more exposure results in more light collected and higher pixel values. However, once the brightest regions reach the 1023 limit, increases in exposure will not raise the max value, and the image becomes overexposed."]},{"cell_type":"markdown","id":"cooked-paragraph","metadata":{"id":"cooked-paragraph"},"source":["# Small aperture and image averaging"]},{"cell_type":"markdown","id":"connected-brooks","metadata":{"id":"connected-brooks"},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Data collection:</b> <font color='black'> Make multiple small aperture image acquisitions <br/><br/>\n","1. Close the aperture until your maximum image value is 80-100. <br/>\n","Show a single image of the slide at these settings and paste it below:\n","</font>\n","</div>"]},{"cell_type":"code","execution_count":4,"id":"developmental-providence","metadata":{"id":"developmental-providence","outputId":"726e4f43-7162-4f7c-f01e-0ab48fb0cafa","executionInfo":{"status":"error","timestamp":1743565964128,"user_tz":240,"elapsed":4,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}},"colab":{"base_uri":"https://localhost:8080/","height":211}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'c' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ce1c5a71a6b5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exposure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"]}],"source":["c.set_exposure(30)\n","\n","\n","i=0\n","while True:\n","    cv2.imshow('Camera', cv2.normalize(c.capture().copy(), None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U))\n","    if cv2.waitKey(30) & 0xFF == ord('s'):\n","        aperture = 20*i\n","        image_10bit = c.capture().copy()\n","        image_8bit = cv2.normalize(image_10bit, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","\n","        fig, ax = plt.subplots(1, figsize=(12, 5))\n","        x = ax.imshow(image_8bit, cmap='gray')\n","        fig.colorbar(x, ax=ax)\n","        plt.savefig(f'image_aperture{aperture}')\n","\n","        plt.clf()\n","\n","        image_10bit = c.capture().copy()\n","        image_8bit = cv2.normalize(image_10bit, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","\n","        fig, ax = plt.subplots(figsize=(12, 5))\n","        ax.hist(image_10bit.flatten(), bins=1024, range=(0, 1023), color='gray')\n","        ax.set_xticks(np.arange(0, 1023, 20))\n","        plt.xticks(rotation=45, fontsize=8)\n","        ax.set_xlabel('Pixel Value (0–1023)')\n","        ax.set_ylabel('Frequency')\n","        ax.set_title(f'Histogram at Aperture {aperture} %')\n","        plt.tight_layout()\n","\n","        plt.savefig(f'histogram_aperture{aperture}.png')\n","        plt.show()\n","\n","        plt.clf()\n","        plt.cla()\n","        i += 1\n","    if cv2.waitKey(30) & 0xFF == ord('q'):\n","        break\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","id":"c2aa5cbe-1305-4cb1-ac4d-f78e0076d206","metadata":{"id":"c2aa5cbe-1305-4cb1-ac4d-f78e0076d206"},"source":["![image_aperture20.png](attachment:f55685d0-3729-403b-8ad4-9a338aced97e.png)![image_aperture23.png](attachment:bc0159d8-a77d-449d-8fe5-8d1a77063c76.png)![image_aperture25.png](attachment:f7d6f89e-2a89-41cd-8d37-165603f52360.png)"]},{"cell_type":"markdown","id":"ac23bb89-76a6-43eb-8788-c41059cdde43","metadata":{"id":"ac23bb89-76a6-43eb-8788-c41059cdde43"},"source":["above image order: aperture level 20% -> 23% -> 25%"]},{"cell_type":"markdown","id":"f911447b-71bb-4574-92c8-32691b70cb44","metadata":{"id":"f911447b-71bb-4574-92c8-32691b70cb44"},"source":["![image_aperture0.png](attachment:5bdc666e-eb7b-4ea6-aacb-310e0f3afb0c.png)"]},{"cell_type":"markdown","id":"c9337cf4-ad94-48b0-83ce-3c28af9a1405","metadata":{"id":"c9337cf4-ad94-48b0-83ce-3c28af9a1405"},"source":["aperture level: 0%"]},{"cell_type":"markdown","id":"fifth-alarm","metadata":{"id":"fifth-alarm"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 2. How is this image different than the good image you showed above? Why? </font>\n","\n","</div>"]},{"cell_type":"markdown","id":"44da2c1a-ef7c-4d3d-93b8-aa659547cdc2","metadata":{"id":"44da2c1a-ef7c-4d3d-93b8-aa659547cdc2"},"source":["This image is different than the well exposed good image above because this image is darker and noisier. It's darker because the small aperture reduces the amount of light that reaches the camera. Also, the signal is low so the random sensor noise becomes more visible, especially in darker regions."]},{"cell_type":"markdown","id":"chicken-jaguar","metadata":{"id":"chicken-jaguar"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 3. Show an average of all the images that were acquired with the small aperture: </font>\n","</div>"]},{"cell_type":"markdown","id":"devoted-fourth","metadata":{"id":"devoted-fourth"},"source":["<div class=\"alert alert-block alert-success\">\n","\n","<font color='black'> 4. What happens when you average many of the images with small image values? Why? </font>\n","</div>"]},{"cell_type":"markdown","id":"ec51a52b-3a26-4619-bef0-dfd4d91e06b4","metadata":{"id":"ec51a52b-3a26-4619-bef0-dfd4d91e06b4"},"source":["When you average a bunch of low-signal images, the random noise kind of cancels itself out because it’s different in each frame. But the actual image — the part that stays the same — gets clearer. So the final image ends up looking smoother and less noisy, even though each individual one was really dim. Basically, averaging helps boost the signal and reduce the noise."]},{"cell_type":"markdown","id":"frank-sally","metadata":{"id":"frank-sally"},"source":["# Moving the filter wheel"]},{"cell_type":"markdown","id":"express-macintosh","metadata":{"id":"express-macintosh"},"source":["<div class=\"alert alert-block alert-success\">\n","<font color='black'> Move the filter wheel to filter 1, 2, and 3 respectively. There are three color filters in the filter wheel: 460 nm (blue), 540 nm (green), and 600 nm (orange). You will obtain one of the following four slides for imaging.<br/><br/>\n","1. What do we need to do to get a good image?<br/>\n","</font>\n","</div>"]},{"cell_type":"markdown","id":"76be4865-cdf6-4051-8013-35c8f7942465","metadata":{"id":"76be4865-cdf6-4051-8013-35c8f7942465"},"source":["To get a good image, we need to adjust the camera settings like exposure time or increase the light intensity because the filters block out a lot of light. We can also adjust the image after by changing the intensity bar afterwards to brighten the image."]},{"cell_type":"markdown","id":"minimal-finding","metadata":{"id":"minimal-finding"},"source":["<img src=\"Lab1\\Bioslide.jpg\" style=\"width:900px\">"]},{"cell_type":"markdown","id":"blessed-formation","metadata":{"id":"blessed-formation"},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Data collection:</b> <font color='black'> Image the biological slide with different color filters <br/><br/>\n","    \n","2. Show the image data below. What effects do the filters have on the images of each slide? Explain why.\n","    \n","</font>\n","</div>"]},{"cell_type":"code","execution_count":null,"id":"8488339b-85f2-4eb1-b383-ad9d5022fca5","metadata":{"id":"8488339b-85f2-4eb1-b383-ad9d5022fca5","executionInfo":{"status":"aborted","timestamp":1743565964126,"user_tz":240,"elapsed":156,"user":{"displayName":"Jonathan Feng","userId":"17716898520433689364"}}},"outputs":[],"source":["i=0\n","while True:\n","    cv2.imshow('Camera', cv2.normalize(c.capture().copy(), None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U))\n","    if cv2.waitKey(30) & 0xFF == ord('s'):\n","        image_10bit = c.capture().copy()\n","        image_8bit = cv2.normalize(image_10bit, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","\n","        fig, ax = plt.subplots(1, figsize=(12, 5))\n","        x = ax.imshow(image_8bit, cmap='gray')\n","        fig.colorbar(x, ax=ax)\n","        plt.savefig(f'image_filter{i}')\n","\n","        plt.clf()\n","\n","        image_10bit = c.capture().copy()\n","        image_8bit = cv2.normalize(image_10bit, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","\n","        fig, ax = plt.subplots(figsize=(12, 5))\n","        ax.hist(image_10bit.flatten(), bins=1024, range=(0, 1023), color='gray')\n","        ax.set_xticks(np.arange(0, 1023, 20))\n","        plt.xticks(rotation=45, fontsize=8)\n","        ax.set_xlabel('Pixel Value (0–1023)')\n","        ax.set_ylabel('Frequency')\n","        ax.set_title(f'Histogram at Filter {i} %')\n","        plt.tight_layout()\n","\n","        plt.savefig(f'histogram_filter{i}.png')\n","        plt.show()\n","\n","        plt.clf()\n","        plt.cla()\n","        i += 1\n","    if cv2.waitKey(30) & 0xFF == ord('q'):\n","        break\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","id":"4cb6adba-9313-4c05-bb67-2e084c40c8ac","metadata":{"id":"4cb6adba-9313-4c05-bb67-2e084c40c8ac"},"source":["![histogram_filter1.png](attachment:9fc7d9af-06f6-41f6-994d-4ca4c40697f0.png)![histogram_filter0.png](attachment:26b975bb-8ece-42e7-8397-7aa1f6cfb326.png)![histogram_filter2.png](attachment:963a0af3-9293-4e59-bd46-6c1c66d60065.png)"]},{"cell_type":"markdown","id":"adc87a87-94d2-4da4-98a5-ed7d165f1df9","metadata":{"id":"adc87a87-94d2-4da4-98a5-ed7d165f1df9"},"source":["![histogram_filter3.png](attachment:25b4f42f-b320-47e3-9baf-b3c372fd6e6c.png)"]},{"cell_type":"markdown","id":"be463558-4bcb-46d0-a268-397155066c24","metadata":{"id":"be463558-4bcb-46d0-a268-397155066c24"},"source":["![image_filter3.png](attachment:18da9081-b711-4e48-bb35-0e731022bd45.png)"]},{"cell_type":"markdown","id":"216efc55-aaee-4c0c-b01a-9936ed15163f","metadata":{"id":"216efc55-aaee-4c0c-b01a-9936ed15163f"},"source":["^image w/ filter 3"]},{"cell_type":"markdown","id":"6da23115-6b0e-4a31-9aff-0273966ce7ff","metadata":{"id":"6da23115-6b0e-4a31-9aff-0273966ce7ff"},"source":["![image_filter0.png](attachment:fe76d56a-e782-49d3-91ed-3fb960a43559.png)![image_filter1.png](attachment:1d7266f3-65f8-47e1-9e97-2a449bbca665.png)![image_filter2.png](attachment:ad0e3f59-8b8d-4d75-b7ea-7f542836c8ab.png)"]},{"cell_type":"markdown","id":"272d4f93-3eec-477d-94ac-86abb4d9e0e2","metadata":{"id":"272d4f93-3eec-477d-94ac-86abb4d9e0e2"},"source":["image order: image w/ filter 0, 1, 2, respectively"]}],"metadata":{"colab":{"provenance":[]},"jupytext":{"encoding":"# -*- coding: utf-8 -*-"},"kernelspec":{"display_name":"Python [conda env:base] *","language":"python","name":"conda-base-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"toc-autonumbering":true,"toc-showcode":false,"toc-showmarkdowntxt":false},"nbformat":4,"nbformat_minor":5}